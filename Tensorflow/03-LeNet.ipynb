{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#使用-Keras-创建第一个卷积神经网络-LeNet\" data-toc-modified-id=\"使用-Keras-创建第一个卷积神经网络-LeNet-1\">使用 Keras 创建第一个卷积神经网络 LeNet</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-导入数据\" data-toc-modified-id=\"1.-导入数据-1.1\">1. 导入数据</a></span></li><li><span><a href=\"#2.-数据预处理\" data-toc-modified-id=\"2.-数据预处理-1.2\">2. 数据预处理</a></span></li><li><span><a href=\"#3.-定义模型\" data-toc-modified-id=\"3.-定义模型-1.3\">3. 定义模型</a></span></li><li><span><a href=\"#4.-开始训练\" data-toc-modified-id=\"4.-开始训练-1.4\">4. 开始训练</a></span></li><li><span><a href=\"#5.-训练结束后评估\" data-toc-modified-id=\"5.-训练结束后评估-1.5\">5. 训练结束后评估</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Keras 创建第一个卷积神经网络 LeNet\n",
    "\n",
    "这一部分我们构造一个比多层感知机更为复杂的基于卷积的神经网络--LeNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "\n",
    "print(tf.VERSION, K.__version__)\n",
    "nn = K.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = K.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "print(train_images.shape, train_labels.shape)\n",
    "print(test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理部分与上一节的内容相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = (image / 255.).astype(np.float32)\n",
    "    label = label.astype(np.int32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(images, labels, batch_size=4, shuffle=True):\n",
    "    assert images.shape[0] == labels.shape[0], \\\n",
    "        \"Shape mismatch: images {} vs labels {}\".format(images.shape, labels.shape)\n",
    "    images, labels = preprocess(images, labels)\n",
    "\n",
    "    while True:\n",
    "        all_indices = np.arange(images.shape[0])\n",
    "        if shuffle:\n",
    "            np.random.shuffle(all_indices)\n",
    "        for i in range(0, all_indices.shape[0], batch_size):\n",
    "            image_batch = images[all_indices[i:i + batch_size]]\n",
    "            label_batch = labels[all_indices[i:i + batch_size]]\n",
    "            yield image_batch, label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们定义一个卷积神经网络 LeNet, 它的结构为 Conv-Pool-Conv-Pool-Conv-Flatten-FC-FC, 其中\n",
    "* Conv: 二维卷积层\n",
    "* Pool: 二维池化层\n",
    "* Flatten: 把二维图像压平成一维向量\n",
    "* FC: 全连接层\n",
    "\n",
    "同时这里我们使用 Keras 的函数式 API, 函数式 API 比序列式 API 的优点是前者可以构造更复杂的网络结构, 如多输入多输出, 层之间的跳跃连接等. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jarvis\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    inputs = K.Input(shape=(28, 28, 1))                         # 28x28@6\n",
    "    out = nn.Conv2D(6, 5, activation=tf.nn.relu, padding=\"same\")(inputs)        # 28x28@6\n",
    "    out = nn.MaxPool2D()(out)                                   # 14x14@6\n",
    "    out = nn.Conv2D(16, 5, activation=tf.nn.relu)(out)          # 10x10@16\n",
    "    out = nn.MaxPool2D()(out)                                   # 5x5@16\n",
    "    out = nn.Conv2D(120, 5, activation=tf.nn.relu)(out)         # 1x1@160\n",
    "    out = nn.Flatten()(out)                                     # 160\n",
    "    out = nn.Dense(84, activation=tf.nn.relu)(out)              # 84\n",
    "    out = nn.Dense(10, activation=tf.nn.softmax)(out)           # 10\n",
    "    return inputs, out\n",
    "\n",
    "x, y = get_model()\n",
    "model = K.Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义模型优化器, 损失函数和评估指标. Tensorflow 中的 Keras 模型在编译时既可以直接指定 `tf.train.AdamOptimizer()` 这类 Tensorflow 的优化器(上一节那样), 也可以通过字符串指定优化器, 就像下面这样."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 开始训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练部分和上一节一模一样, 我们仅仅修改了模型搭建的部分.\n",
    "首先创建用于训练和验证的数据生成器. \n",
    "\n",
    "**注意:** 这里我们给 `train_images` 和 `test_images` 都增加了一个维度, 其形状变成了 `[60000, 28, 28, 1]` 和 `[10000, 28, 28, 1]`. 这样做的目的是 Keras 中的卷积操作 `Conv2D` 要求数据的输入尺寸为 `[batch_size, height, width, channel]`, 所以我们必须补一维通道. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_gen = data_loader(train_images[..., None], train_labels, batch_size=batch_size)\n",
    "val_gen = data_loader(test_images[..., None], test_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们使用 `fit_generator` 函数, 同时提供训练生成器和验证生成器. Keras 会在每个 epoch 结束的时候评估验证集的数据, 并输出验证集上的准确率."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.3681 - acc: 0.8662\n",
      "3750/3750 [==============================] - 72s 19ms/step - loss: 0.4895 - acc: 0.8205 - val_loss: 0.3681 - val_acc: 0.8662\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.3262 - acc: 0.8818\n",
      "3750/3750 [==============================] - 85s 23ms/step - loss: 0.3282 - acc: 0.8791 - val_loss: 0.3262 - val_acc: 0.8818\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.3016 - acc: 0.8906\n",
      "3750/3750 [==============================] - 89s 24ms/step - loss: 0.2851 - acc: 0.8937 - val_loss: 0.3016 - val_acc: 0.8906\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.2786 - acc: 0.8974\n",
      "3750/3750 [==============================] - 94s 25ms/step - loss: 0.2589 - acc: 0.9031 - val_loss: 0.2786 - val_acc: 0.8974\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.2893 - acc: 0.8930\n",
      "3750/3750 [==============================] - 90s 24ms/step - loss: 0.2387 - acc: 0.9104 - val_loss: 0.2893 - val_acc: 0.8930\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.2794 - acc: 0.8994\n",
      "3750/3750 [==============================] - 102s 27ms/step - loss: 0.2214 - acc: 0.9169 - val_loss: 0.2794 - val_acc: 0.8994\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.3176 - acc: 0.8863\n",
      "3750/3750 [==============================] - 93s 25ms/step - loss: 0.2085 - acc: 0.9202 - val_loss: 0.3176 - val_acc: 0.8863\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 5s 9ms/step - loss: 0.2879 - acc: 0.9015\n",
      "3750/3750 [==============================] - 90s 24ms/step - loss: 0.1960 - acc: 0.9254 - val_loss: 0.2879 - val_acc: 0.9015\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.2762 - acc: 0.9042\n",
      "3750/3750 [==============================] - 89s 24ms/step - loss: 0.1870 - acc: 0.9284 - val_loss: 0.2762 - val_acc: 0.9042\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.2930 - acc: 0.8980\n",
      "3750/3750 [==============================] - 90s 24ms/step - loss: 0.1755 - acc: 0.9330 - val_loss: 0.2930 - val_acc: 0.8980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28d32169cc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen, steps_per_epoch=train_labels.shape[0] // batch_size, epochs=10,\n",
    "                    validation_data=val_gen, validation_steps=test_labels.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 训练结束后评估\n",
    "\n",
    "这里我们评估也使用生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8994\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(val_gen, steps=test_labels.shape[0] // batch_size)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 LeNet 的识别准确率要高于单隐层的神经网络, 有大约0.02的提升."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
