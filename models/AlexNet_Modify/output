step 00000: loss=4.6843 (45.3 examples/sec; 2.826 sec/batch)
step 00020: loss=3.1472 (326.3 examples/sec; 0.392 sec/batch)
step 00040: loss=2.4356 (325.7 examples/sec; 0.393 sec/batch)
step 00060: loss=2.1370 (324.8 examples/sec; 0.394 sec/batch)
step 00080: loss=1.9650 (323.5 examples/sec; 0.396 sec/batch)
step 00100: loss=1.9002 (322.9 examples/sec; 0.396 sec/batch)
step 00120: loss=1.8696 (330.6 examples/sec; 0.387 sec/batch)
step 00140: loss=1.8465 (320.0 examples/sec; 0.400 sec/batch)
step 00160: loss=1.6531 (325.4 examples/sec; 0.393 sec/batch)
step 00180: loss=1.6518 (321.6 examples/sec; 0.398 sec/batch)
step 00200: loss=1.4346 (327.3 examples/sec; 0.391 sec/batch)
step 00220: loss=1.8239 (327.4 examples/sec; 0.391 sec/batch)
step 00240: loss=1.8306 (324.4 examples/sec; 0.395 sec/batch)
step 00260: loss=1.5490 (328.1 examples/sec; 0.390 sec/batch)
step 00280: loss=1.5086 (326.4 examples/sec; 0.392 sec/batch)
step 00300: loss=1.5221 (330.5 examples/sec; 0.387 sec/batch)
step 00320: loss=1.5936 (327.3 examples/sec; 0.391 sec/batch)
step 00340: loss=1.3570 (326.7 examples/sec; 0.392 sec/batch)
step 00360: loss=1.3637 (326.7 examples/sec; 0.392 sec/batch)
step 00380: loss=1.6645 (331.4 examples/sec; 0.386 sec/batch)
step 00400: loss=1.5501 (330.6 examples/sec; 0.387 sec/batch)
step 00420: loss=1.5619 (326.8 examples/sec; 0.392 sec/batch)
step 00440: loss=1.4351 (329.7 examples/sec; 0.388 sec/batch)
step 00460: loss=1.5899 (330.4 examples/sec; 0.387 sec/batch)
step 00480: loss=1.4601 (330.3 examples/sec; 0.388 sec/batch)
step 00500: loss=1.6382 (330.9 examples/sec; 0.387 sec/batch)
step 00520: loss=1.5206 (330.6 examples/sec; 0.387 sec/batch)
step 00540: loss=1.5507 (330.0 examples/sec; 0.388 sec/batch)
step 00560: loss=1.4859 (329.3 examples/sec; 0.389 sec/batch)
step 00580: loss=1.5023 (330.2 examples/sec; 0.388 sec/batch)
step 00600: loss=1.5203 (330.1 examples/sec; 0.388 sec/batch)
step 00620: loss=1.5113 (335.6 examples/sec; 0.381 sec/batch)
step 00640: loss=1.4618 (328.8 examples/sec; 0.389 sec/batch)
step 00660: loss=1.1931 (329.0 examples/sec; 0.389 sec/batch)
step 00680: loss=1.3749 (324.7 examples/sec; 0.394 sec/batch)
step 00700: loss=1.3747 (329.0 examples/sec; 0.389 sec/batch)
step 00720: loss=1.1557 (328.3 examples/sec; 0.390 sec/batch)
step 00740: loss=1.2959 (326.2 examples/sec; 0.392 sec/batch)
step 00760: loss=1.4424 (330.7 examples/sec; 0.387 sec/batch)
step 00780: loss=1.3825 (334.0 examples/sec; 0.383 sec/batch)
step 00800: loss=1.2808 (328.1 examples/sec; 0.390 sec/batch)
step 00820: loss=1.2976 (330.6 examples/sec; 0.387 sec/batch)
step 00840: loss=1.2637 (326.1 examples/sec; 0.393 sec/batch)
step 00860: loss=1.3300 (325.8 examples/sec; 0.393 sec/batch)
step 00880: loss=1.3864 (322.6 examples/sec; 0.397 sec/batch)
step 00900: loss=1.2721 (302.7 examples/sec; 0.423 sec/batch)
step 00920: loss=1.4520 (333.0 examples/sec; 0.384 sec/batch)
step 00940: loss=1.3694 (333.7 examples/sec; 0.384 sec/batch)
step 00960: loss=1.2306 (328.2 examples/sec; 0.390 sec/batch)
step 00980: loss=1.4670 (328.3 examples/sec; 0.390 sec/batch)
step 01000: loss=1.3189 (333.4 examples/sec; 0.384 sec/batch)
step 01020: loss=1.2060 (327.8 examples/sec; 0.390 sec/batch)
step 01040: loss=1.2494 (333.5 examples/sec; 0.384 sec/batch)
step 01060: loss=1.1566 (329.8 examples/sec; 0.388 sec/batch)
step 01080: loss=1.0758 (327.7 examples/sec; 0.391 sec/batch)
step 01100: loss=1.2607 (329.7 examples/sec; 0.388 sec/batch)
step 01120: loss=1.3224 (330.0 examples/sec; 0.388 sec/batch)
step 01140: loss=1.3439 (331.8 examples/sec; 0.386 sec/batch)
step 01160: loss=1.1283 (333.0 examples/sec; 0.384 sec/batch)
step 01180: loss=1.2584 (332.3 examples/sec; 0.385 sec/batch)
step 01200: loss=1.5473 (331.6 examples/sec; 0.386 sec/batch)
step 01220: loss=1.1835 (324.6 examples/sec; 0.394 sec/batch)
step 01240: loss=1.3425 (334.3 examples/sec; 0.383 sec/batch)
step 01260: loss=1.2696 (331.0 examples/sec; 0.387 sec/batch)
step 01280: loss=1.2568 (331.1 examples/sec; 0.387 sec/batch)
step 01300: loss=1.3916 (334.9 examples/sec; 0.382 sec/batch)
step 01320: loss=1.3155 (330.4 examples/sec; 0.387 sec/batch)
step 01340: loss=1.4126 (325.1 examples/sec; 0.394 sec/batch)
step 01360: loss=1.1613 (314.4 examples/sec; 0.407 sec/batch)
step 01380: loss=1.1457 (332.4 examples/sec; 0.385 sec/batch)
step 01400: loss=1.3874 (323.2 examples/sec; 0.396 sec/batch)
step 01420: loss=1.2757 (329.7 examples/sec; 0.388 sec/batch)
step 01440: loss=1.1137 (330.6 examples/sec; 0.387 sec/batch)
step 01460: loss=1.1764 (332.2 examples/sec; 0.385 sec/batch)
step 01480: loss=1.2630 (326.3 examples/sec; 0.392 sec/batch)
step 01500: loss=1.0802 (331.8 examples/sec; 0.386 sec/batch)
step 01520: loss=1.2300 (337.4 examples/sec; 0.379 sec/batch)
step 01540: loss=1.1308 (333.2 examples/sec; 0.384 sec/batch)
step 01560: loss=1.1007 (331.8 examples/sec; 0.386 sec/batch)
step 01580: loss=1.2580 (331.3 examples/sec; 0.386 sec/batch)
step 01600: loss=1.0879 (328.8 examples/sec; 0.389 sec/batch)
step 01620: loss=1.1545 (323.8 examples/sec; 0.395 sec/batch)
step 01640: loss=1.2262 (333.2 examples/sec; 0.384 sec/batch)
step 01660: loss=1.3144 (327.4 examples/sec; 0.391 sec/batch)
step 01680: loss=1.2335 (330.4 examples/sec; 0.387 sec/batch)
step 01700: loss=1.2443 (329.1 examples/sec; 0.389 sec/batch)
step 01720: loss=1.2495 (328.8 examples/sec; 0.389 sec/batch)
step 01740: loss=1.1613 (326.4 examples/sec; 0.392 sec/batch)
step 01760: loss=1.1338 (329.0 examples/sec; 0.389 sec/batch)
step 01780: loss=1.0937 (329.0 examples/sec; 0.389 sec/batch)
step 01800: loss=1.2732 (327.2 examples/sec; 0.391 sec/batch)
step 01820: loss=1.0341 (316.8 examples/sec; 0.404 sec/batch)
step 01840: loss=1.2524 (332.6 examples/sec; 0.385 sec/batch)
step 01860: loss=1.1012 (330.8 examples/sec; 0.387 sec/batch)
step 01880: loss=1.2370 (323.9 examples/sec; 0.395 sec/batch)
step 01900: loss=1.1604 (328.7 examples/sec; 0.389 sec/batch)
step 01920: loss=1.2114 (331.2 examples/sec; 0.386 sec/batch)
step 01940: loss=1.0776 (331.2 examples/sec; 0.387 sec/batch)
step 01960: loss=1.1437 (334.3 examples/sec; 0.383 sec/batch)
step 01980: loss=1.0826 (328.8 examples/sec; 0.389 sec/batch)
step 02000: loss=1.1141 (335.0 examples/sec; 0.382 sec/batch)
step 02020: loss=1.0090 (330.3 examples/sec; 0.388 sec/batch)
step 02040: loss=1.1009 (329.9 examples/sec; 0.388 sec/batch)
step 02060: loss=1.1887 (331.8 examples/sec; 0.386 sec/batch)
step 02080: loss=1.0666 (329.7 examples/sec; 0.388 sec/batch)
step 02100: loss=1.0063 (323.1 examples/sec; 0.396 sec/batch)
step 02120: loss=1.3236 (320.8 examples/sec; 0.399 sec/batch)
step 02140: loss=1.2575 (335.3 examples/sec; 0.382 sec/batch)
step 02160: loss=1.1029 (328.5 examples/sec; 0.390 sec/batch)
step 02180: loss=1.0363 (329.0 examples/sec; 0.389 sec/batch)
step 02200: loss=1.0629 (329.1 examples/sec; 0.389 sec/batch)
step 02220: loss=1.0201 (327.9 examples/sec; 0.390 sec/batch)
step 02240: loss=1.1205 (326.4 examples/sec; 0.392 sec/batch)
step 02260: loss=0.9586 (326.4 examples/sec; 0.392 sec/batch)
step 02280: loss=0.9752 (331.4 examples/sec; 0.386 sec/batch)
step 02300: loss=1.1585 (307.8 examples/sec; 0.416 sec/batch)
step 02320: loss=1.2884 (334.4 examples/sec; 0.383 sec/batch)
step 02340: loss=1.0500 (335.8 examples/sec; 0.381 sec/batch)
step 02360: loss=0.9783 (327.0 examples/sec; 0.391 sec/batch)
step 02380: loss=1.1446 (330.4 examples/sec; 0.387 sec/batch)
step 02400: loss=1.3082 (330.9 examples/sec; 0.387 sec/batch)
step 02420: loss=0.8816 (324.7 examples/sec; 0.394 sec/batch)
step 02440: loss=1.1224 (334.2 examples/sec; 0.383 sec/batch)
step 02460: loss=1.0096 (328.0 examples/sec; 0.390 sec/batch)
step 02480: loss=1.2475 (337.9 examples/sec; 0.379 sec/batch)
step 02500: loss=1.1239 (331.0 examples/sec; 0.387 sec/batch)
step 02520: loss=1.1779 (330.1 examples/sec; 0.388 sec/batch)
step 02540: loss=1.0763 (334.3 examples/sec; 0.383 sec/batch)
step 02560: loss=1.0752 (334.0 examples/sec; 0.383 sec/batch)
step 02580: loss=1.0298 (335.9 examples/sec; 0.381 sec/batch)
step 02600: loss=1.0650 (333.3 examples/sec; 0.384 sec/batch)
step 02620: loss=1.1281 (330.2 examples/sec; 0.388 sec/batch)
step 02640: loss=1.1080 (333.1 examples/sec; 0.384 sec/batch)
step 02660: loss=1.0730 (338.8 examples/sec; 0.378 sec/batch)
step 02680: loss=1.0225 (333.1 examples/sec; 0.384 sec/batch)
step 02700: loss=1.0598 (330.7 examples/sec; 0.387 sec/batch)
step 02720: loss=1.0856 (333.2 examples/sec; 0.384 sec/batch)
step 02740: loss=1.1594 (314.1 examples/sec; 0.408 sec/batch)
step 02760: loss=1.2496 (327.4 examples/sec; 0.391 sec/batch)
step 02780: loss=1.0209 (334.1 examples/sec; 0.383 sec/batch)
step 02800: loss=1.1926 (335.2 examples/sec; 0.382 sec/batch)
step 02820: loss=1.0974 (333.5 examples/sec; 0.384 sec/batch)
step 02840: loss=1.1312 (333.2 examples/sec; 0.384 sec/batch)
step 02860: loss=1.1711 (330.9 examples/sec; 0.387 sec/batch)
step 02880: loss=1.0726 (324.5 examples/sec; 0.394 sec/batch)
step 02900: loss=1.2738 (331.2 examples/sec; 0.386 sec/batch)
step 02920: loss=1.1162 (331.3 examples/sec; 0.386 sec/batch)
step 02940: loss=1.2137 (332.7 examples/sec; 0.385 sec/batch)
step 02960: loss=1.0408 (334.0 examples/sec; 0.383 sec/batch)
step 02980: loss=0.9860 (334.9 examples/sec; 0.382 sec/batch)
Precision @ 1 = 0.708